{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Análise Exploratória (EDA) e Modelagem Preditiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** Este notebook realiza a análise exploratória dos dados tratados e desenvolve um modelo de machine learning para prever o número de casos de violência.\n",
    "\n",
    "**Passos:**\n",
    "1. **Carregamento dos Dados:** Carregar o dataset tratado (`violencia_tratado.csv`).\n",
    "2. **Análise Exploratória (EDA):**\n",
    "   - Gerar gráficos de tendência.\n",
    "   - Analisar correlações entre variáveis.\n",
    "3. **Preparação para Modelagem:**\n",
    "   - Selecionar features (variáveis preditoras) e target (variável alvo).\n",
    "   - Dividir os dados em conjuntos de treino e teste.\n",
    "4. **Treinamento e Avaliação:**\n",
    "   - Treinar modelos de Regressão (Random Forest e XGBoost).\n",
    "   - Avaliar os modelos usando métricas como MAE, RMSE e R².\n",
    "5. **Seleção e Salvamento do Modelo:**\n",
    "   - Escolher o modelo com melhor desempenho.\n",
    "   - Salvar o modelo treinado no arquivo `model.pkl` para ser usado pela aplicação Flet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define o tema padrão para os gráficos do Plotly\n",
    "px.defaults.template = \"plotly_dark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Geração de Dados Simulados ---\n",
    "# Em um cenário real, você carregaria o CSV gerado no notebook 01.\n",
    "# Como não temos o notebook 01, vamos criar um DataFrame simulado mais robusto aqui.\n",
    "\n",
    "# Construir caminhos absolutos para garantir que os arquivos sejam salvos no lugar certo\n",
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path().cwd() # O diretório de trabalho atual\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / 'data' / 'processed' / 'violencia_tratado.csv'\n",
    "MODEL_PATH = PROJECT_ROOT / 'model.pkl'\n",
    "\n",
    "def gerar_dados_simulados(path):\n",
    "    print(\"Gerando dados simulados, pois o arquivo tratado não foi encontrado...\")\n",
    "    anos = range(2015, 2023)\n",
    "    estados = ['SP', 'RJ', 'MG', 'BA']\n",
    "    tipos_violencia = ['Doméstica', 'Sexual', 'Psicológica']\n",
    "    faixas_etarias = ['10-19 anos', '20-29 anos', '30-39 anos']\n",
    "    \n",
    "    data = []\n",
    "    for ano in anos:\n",
    "        for estado in estados:\n",
    "            for tipo in tipos_violencia:\n",
    "                for faixa in faixas_etarias:\n",
    "                    # Fatores base para simulação\n",
    "                    base_casos = 100 + estados.index(estado) * 50 + tipos_violencia.index(tipo) * 20\n",
    "                    tendencia_temporal = (ano - 2015) * 10\n",
    "                    ruido = np.random.randint(-20, 20)\n",
    "                    \n",
    "                    # Simulação de indicadores socioeconômicos\n",
    "                    idhm = 0.75 + (estados.index(estado) * 0.02) + (ano - 2015) * 0.005 + np.random.uniform(-0.01, 0.01)\n",
    "                    taxa_desemprego = 12.0 - (estados.index(estado) * 0.5) - (ano - 2015) * 0.2 + np.random.uniform(-0.5, 0.5)\n",
    "                    renda_media = 1200 + (estados.index(estado) * 100) + (ano - 2015) * 50 + np.random.uniform(-50, 50)\n",
    "                    \n",
    "                    # Fórmula para o número de casos\n",
    "                    casos = base_casos + tendencia_temporal + ruido - (idhm * 50) + (taxa_desemprego * 5) - (renda_media * 0.01)\n",
    "                    \n",
    "                    data.append({\n",
    "                        'ano': ano,\n",
    "                        'estado': estado,\n",
    "                        'tipo_violencia': tipo,\n",
    "                        'faixa_etaria': faixa,\n",
    "                        'casos': int(max(0, casos)),\n",
    "                        'idhm': round(idhm, 3),\n",
    "                        'taxa_desemprego': round(taxa_desemprego, 2),\n",
    "                        'renda_media': int(renda_media)\n",
    "                    })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    # Garantir que o diretório exista\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    df.to_csv(path, index=False)\n",
    "    return df\n",
    "\n",
    "# Tenta carregar os dados, se não encontrar, gera dados simulados\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"Dados carregados de {DATA_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    df = gerar_dados_simulados(DATA_PATH)\n",
    "\n",
    "df['ano'] = pd.to_datetime(df['ano'], format='%Y')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise Exploratória de Dados (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Tendência de Casos por Ano (Total Brasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_por_ano = df.groupby(df['ano'].dt.year)['casos'].sum().reset_index()\n",
    "\n",
    "fig = px.line(casos_por_ano, x='ano', y='casos', title='Evolução do Total de Casos de Violência por Ano', \n",
    "              markers=True, labels={'ano': 'Ano', 'casos': 'Número Total de Casos'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Distribuição de Casos por Estado e Tipo de Violência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_agrupados = df.groupby(['estado', 'tipo_violencia'])['casos'].sum().reset_index()\n",
    "\n",
    "fig = px.bar(casos_agrupados, x='estado', y='casos', color='tipo_violencia', \n",
    "             title='Total de Casos por Estado e Tipo de Violência', barmode='group',\n",
    "             labels={'estado': 'Estado', 'casos': 'Número Total de Casos', 'tipo_violencia': 'Tipo de Violência'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Correlação entre Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df[['casos', 'idhm', 'taxa_desemprego', 'renda_media']]\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "                    z=correlation_matrix.values,\n",
    "                    x=correlation_matrix.columns,\n",
    "                    y=correlation_matrix.columns,\n",
    "                    colorscale='RdBu_r', # Escala de cor (vermelho-azul)\n",
    "                    zmin=-1, zmax=1, # Fixa a escala de -1 a 1\n",
    "                    text=correlation_matrix.round(2).values,\n",
    "                    texttemplate=\"%{text}\"))\n",
    "\n",
    "fig.update_layout(title='Mapa de Calor: Correlação entre Casos e Indicadores Socioeconômicos')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparação para Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O modelo irá prever o número de 'casos' com base nos indicadores socioeconômicos.\n",
    "# As variáveis categóricas (estado, tipo, etc.) são usadas para filtrar os dados na aplicação,\n",
    "# mas não serão usadas como features diretas neste modelo simplificado.\n",
    "\n",
    "features = ['idhm', 'taxa_desemprego', 'renda_media']\n",
    "target = 'casos'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Dividir os dados em 80% para treino e 20% para teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Treinamento e Avaliação de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para armazenar os modelos\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Dicionário para armazenar os resultados\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Treinar o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Fazer previsões no conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcular as métricas\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    results[name] = {'MAE': mae, 'RMSE': rmse, 'R²': r2}\n",
    "    \n",
    "    print(f\"--- Resultados para {name} ---\")\n",
    "    print(f\"MAE (Erro Médio Absoluto): {mae:.2f}\")\n",
    "    print(f\"RMSE (Raiz do Erro Quadrático Médio): {rmse:.2f}\")\n",
    "    print(f\"R² (Coeficiente de Determinação): {r2:.2f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Converter resultados para um DataFrame para fácil visualização\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Seleção e Salvamento do Melhor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar o melhor modelo com base no R² (quanto maior, melhor)\n",
    "best_model_name = results_df['R²'].idxmax()\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"O melhor modelo é: {best_model_name} com R² de {results_df.loc[best_model_name, 'R²']:.2f}\")\n",
    "\n",
    "# Salvar o modelo treinado em um arquivo .pkl\n",
    "joblib.dump(best_model, MODEL_PATH)\n",
    "\n",
    "print(f\"Modelo salvo com sucesso em: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste Rápido do Modelo Carregado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo para garantir que ele foi salvo corretamente\n",
    "loaded_model = joblib.load(MODEL_PATH)\n",
    "\n",
    "# Criar um exemplo de dados para previsão\n",
    "exemplo_dados = pd.DataFrame({\n",
    "    'idhm': [0.8],\n",
    "    'taxa_desemprego': [10.5],\n",
    "    'renda_media': [1800]\n",
    "})\n",
    "\n",
    "# Fazer uma previsão\n",
    "previsao = loaded_model.predict(exemplo_dados)\n",
    "\n",
    "print(f\"Exemplo de dados para previsão:\\n{exemplo_dados}\\n\")\n",
    "print(f\"Previsão de casos: {int(previsao[0])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}